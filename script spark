Spark script(bystate):

tF = sc.textFile("s3://aadhaar-data/*.csv")
pairs = tF.map(lambda x:(x.split(",")[2],int(x.split(",")[8])))
pairs.groupByKey().mapValues(sum).collect()
